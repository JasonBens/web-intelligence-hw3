{
 "metadata": {
  "name": "",
  "signature": "sha256:55684ead72577bb1e9737b5e116ab245d7b7101c4d04f0ad4002d46c989583dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "\n",
      "import glob\n",
      "import mincemeat\n",
      "import cPickle as pickle\n",
      "\n",
      "# Note: spawn connected ipython console with '>ipython console --existing'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get names of all files\n",
      "text_files = glob.glob('hw3data/*')\n",
      "#print text_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def file_contents(file_name):\n",
      "    with open(file_name) as f:\n",
      "        return f.read()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create dictionary of {fileid: documentid:::authors:::title}\n",
      "source = dict((file_name, file_contents(file_name))\n",
      "              for file_name in text_files)\n",
      "#print source[source.keys()[0]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Finds incidences of keywords for each author.\n",
      "\n",
      "# Receives (fileid:documentid:::authors:::title)\n",
      "# Emits (author, keyword)\n",
      "# TODO: check how hyphens are being handled\n",
      "def mapfn(key, value):\n",
      "    # Determine author and relevant keywords from structured file\n",
      "    \n",
      "    import re\n",
      "    \n",
      "    all_stop_words={'about':1, 'above':1, 'after':1, 'again':1, 'against':1, 'all':1, 'am':1, 'an':1, 'and':1, 'any':1, 'are':1, 'arent':1, 'as':1, 'at':1, 'be':1, 'because':1, 'been':1, 'before':1, 'being':1, 'below':1, 'between':1, 'both':1, 'but':1, 'by':1, 'cant':1, 'cannot':1, 'could':1, 'couldnt':1, 'did':1, 'didnt':1, 'do':1, 'does':1, 'doesnt':1, 'doing':1, 'dont':1, 'down':1, 'during':1, 'each':1, 'few':1, 'for':1, 'from':1, 'further':1, 'had':1, 'hadnt':1, 'has':1, 'hasnt':1, 'have':1, 'havent':1, 'having':1, 'he':1, 'hed':1, 'hell':1, 'hes':1, 'her':1, 'here':1, 'heres':1, 'hers':1, 'herself':1, 'him':1, 'himself':1, 'his':1, 'how':1, 'hows':1, 'i':1, 'id':1, 'ill':1, 'im':1, 'ive':1, 'if':1, 'in':1, 'into':1, 'is':1, 'isnt':1, 'it':1, 'its':1, 'its':1, 'itself':1, 'lets':1, 'me':1, 'more':1, 'most':1, 'mustnt':1, 'my':1, 'myself':1, 'no':1, 'nor':1, 'not':1, 'of':1, 'off':1, 'on':1, 'once':1, 'only':1, 'or':1, 'other':1, 'ought':1, 'our':1, 'ours ':1, 'ourselves':1, 'out':1, 'over':1, 'own':1, 'same':1, 'shant':1, 'she':1, 'shed':1, 'shell':1, 'shes':1, 'should':1, 'shouldnt':1, 'so':1, 'some':1, 'such':1, 'than':1, 'that':1, 'thats':1, 'the':1, 'their':1, 'theirs':1, 'them':1, 'themselves':1, 'then':1, 'there':1, 'theres':1, 'these':1, 'they':1, 'theyd':1, 'theyll':1, 'theyre':1, 'theyve':1, 'this':1, 'those':1, 'through':1, 'to':1, 'too':1, 'under':1, 'until':1, 'up':1, 'very':1, 'was':1, 'wasnt':1, 'we':1, 'wed':1, 'well':1, 'were':1, 'weve':1, 'were':1, 'werent':1, 'what':1, 'whats':1, 'when':1, 'whens':1, 'where':1, 'wheres':1, 'which':1, 'while':1, 'who':1, 'whos':1, 'whom':1, 'why':1, 'whys':1, 'with':1, 'wont':1, 'would':1, 'wouldnt':1, 'you':1, 'youd':1, 'youll':1, 'youre':1, 'youve':1, 'your':1, 'yours':1, 'yourself':1, 'yourselves':1}\n",
      "    \n",
      "    for line in value.splitlines():\n",
      "        # Make list of authors and list of terms.  Discard document id\n",
      "        tokens = line.split(':::')[1:]\n",
      "        author_list = tokens[0].lower().split('::')\n",
      "        # remove punctuation and split title into individual terms\n",
      "        term_list = re.sub(r'[^a-zA-Z0-9 ]', '', tokens[1].lower()).split()\n",
      "        # Remove stop words and single letter words\n",
      "        term_list = [term for term in term_list\n",
      "                     if len(term) > 1 and term not in all_stop_words]        \n",
      "        \n",
      "        for author in author_list:\n",
      "            for term in term_list:\n",
      "                yield(author, term)\n",
      "                \n",
      "# Receives (author, [keyword1, keyword2, ...]) (keywords may repeat)\n",
      "# Emits (author, [(term1:count), (term2:count)...])\n",
      "def reducefn(key, value):\n",
      "    # Count number of occurrences of keyword per author.\n",
      "    \n",
      "    unique_terms = set(value)\n",
      "    term = [(t, value.count(t)) for t in unique_terms]\n",
      "    return (key, term)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = mincemeat.Server()\n",
      "s.datasource = source\n",
      "s.mapfn = mapfn\n",
      "s.reducefn = reducefn\n",
      "\n",
      "results = s.run_server(password=\"changeme\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('output.pkl', 'wb') as pklfile:\n",
      "    pickle.dump(results, pklfile)\n",
      "with open('output.txt', 'a') as outfile:\n",
      "    for result in results.values():\n",
      "        outfile.write('{}:: '.format(result[0]))\n",
      "        [outfile.write('{}:{} '.format(r[0], r[1])) for r in result[1]]\n",
      "        outfile.write('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    }
   ],
   "metadata": {}
  }
 ]
}